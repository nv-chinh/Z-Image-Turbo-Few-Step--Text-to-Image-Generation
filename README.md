# Z-Image Turbo: Fewâ€‘Step Textâ€‘toâ€‘Image Generation

## Overview

**Z-Image Turbo** is a fast **text-to-image diffusion inference project** built on top of the Z-Image architecture. It focuses on generating high-quality images using **only a few denoising steps** to reduce inference latency, making it suitable for interactive applications and large-scale deployment.

This repository focuses on inference usage only â€” how to run Zâ€‘Image Turbo for textâ€‘toâ€‘image generation, and how its internal pipeline works.

---

## Features

- âš¡ **Fast inference** with very few denoising steps  
- ğŸ§  **Diffusion Transformer (DiT)** backbone  
- ğŸ“ Strong text understanding via **Qwen3-4B text encoder**  
- ğŸ–¼ï¸ High-quality image decoding using **Flux VAE**
- ğŸ” Deterministic and stable sampling, ideal for production use
- ğŸ§© Modular design, easy to integrate with existing diffusion pipelines

---

## Model Pipeline

Below is the endâ€‘toâ€‘end pipeline for textâ€‘toâ€‘image inference using Zâ€‘Image Turbo:
- **Text Prompt**
  â†“
- **Text Encoder (Qwen3-4B)**
  â†“
- **Text Embeddings**
  â†“
- **Gaussian Noise Latents (z_T)**
  â†“
- **Few-Step Diffusion Transformer (Z-Image Turbo)**
  â†“
- **Denoised Latents (z_0)**
  â†“
- **VAE Decoder (Flux VAE)**
  â†“
- **Final RGB Image**

